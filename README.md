# Scrapy_quotes
Web scraper на основе библиотеки Scrapy, собирающий данные с сайта https://quotes.toscrape.com/ 

Проект включает два паука:  QuotesSpider и AuthorSpider.

```QuotesSpider```: сбор данных о цитатах (текст цитаты, автор и теги).

  Описание работы:
  пауку передаются страницы с цитатами, где он собирает текст цитаты, имя автора и список тегов.
    
    1. Сбор данных о каждой цитате на текущей странице.
    2. Переход на следующую страницу (если таковая имеется) и повторение процесса.
    
```AuthorSpider```: сбор данных об авторах (имя, дата и место рождения).
  
  Описание работы:
  Пауку передается список ссылок на страницы авторов, где он извлекает имя, дату рождения и место рождения автора.
    
    1. Извлечение всех ссылок на авторов с каждой страницы.
    2. Переход на каждую страницу автора и сбор информации.
    3. Переход на следующую страницу (если таковая имеется) и повторение процесса.

```Scrapy``` обладает более высокой производительностью и удобной системой управления асинхронными запросами по сравнению с другими библиотеками (например bs4, requests). Он особенно хорошо подходит для сайтов, где нужно переходить на множество страниц.

Сайт имеет две разные структуры данных: одну для цитат и другую для авторов. Разделение на два паука упрощает организацию и управление сбором данных. Каждый паук сосредоточен на своей конкретной задаче.

```custom_settings``` позволяют переопределять настройки Scrapy для конкретного паука. Это позволяет сохранять результаты в отдельных JSON-файлах для удобства анализа.

## Разверните репозиторий на своем серевере.

1. Клонируйте репозиторий:
```
git clone git@github.com:pitbul892/Scrapy_quotes.git
```
2. Создайте и активируйте виртуальное окружения:
```
py -m venv venv
source venv/bin/activate
```
3. Установите зависимости:
```
pip install -r requirements.txt
```
4. Для запуска паука ```QuotesSpider```:
```
scrapy crawl quotes
```
результаты появятся в файлах ```quotes_text.json``` и ```quotes_author.json```.
5. Для запуска паука ```AuthorSpider```:
```
scrapy crawl authors
```
результаты появятся в файле ```authors.json```.
